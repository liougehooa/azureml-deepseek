{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796cf06d-e4d3-422e-8301-a961e9520f52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DeepSeek R1 Distillation 70B vLLM serving using the Azure ML Python SDK\n",
    "\n",
    "> [1] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.<br>[2] Please make sure you prepare [Hugging Face API Token](https://huggingface.co/docs/hub/security-tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90e6a5-b61d-43fb-b897-75dd35b48363",
   "metadata": {},
   "source": [
    "You may need to install `azure-ai-ml` and `azure-identity` before start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4ab4eb-5810-4fec-9906-3660855554e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -q azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb139b1d-500c-4ef2-9af3-728f2a5ea05f",
   "metadata": {},
   "source": [
    "## 1. Load config file\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234c47-b3e5-4218-8a98-3988c8991643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:23:18,173 - logger - DEBUG - ===== 0. Azure ML Deployment Info =====\n",
      "2025-03-06 02:23:18,174 - logger - DEBUG - AZURE_SUBSCRIPTION_ID=e56790f8-0506-49eb-95b8-82817828d59d\n",
      "2025-03-06 02:23:18,175 - logger - DEBUG - AZURE_RESOURCE_GROUP=dev\n",
      "2025-03-06 02:23:18,175 - logger - DEBUG - AZURE_WORKSPACE=test-vllm\n",
      "2025-03-06 02:23:18,176 - logger - DEBUG - HF_MODEL_NAME_OR_PATH=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "2025-03-06 02:23:18,177 - logger - DEBUG - azure_env_name=ds-qwen-s-env\n",
      "2025-03-06 02:23:18,178 - logger - DEBUG - azure_model_name=ds-qwen-s-model\n",
      "2025-03-06 02:23:18,178 - logger - DEBUG - azure_endpoint_name=ds-qwen-s-ep\n",
      "2025-03-06 02:23:18,179 - logger - DEBUG - azure_deployment_name=blue\n",
      "2025-03-06 02:23:18,179 - logger - DEBUG - azure_serving_cluster_size=Standard_NC6s_v3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from logger import logger\n",
    "from datetime import datetime\n",
    "\n",
    "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "HF_MODEL_NAME_OR_PATH = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "\n",
    "with open(\"config.yml\") as f:\n",
    "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "AZURE_SUBSCRIPTION_ID = d[\"config\"][\"AZURE_SUBSCRIPTION_ID\"]\n",
    "AZURE_RESOURCE_GROUP = d[\"config\"][\"AZURE_RESOURCE_GROUP\"]\n",
    "AZURE_WORKSPACE = d[\"config\"][\"AZURE_WORKSPACE\"]\n",
    "HF_TOKEN = d[\"config\"][\"HF_TOKEN\"]\n",
    "IS_DEBUG = d[\"config\"][\"IS_DEBUG\"]\n",
    "\n",
    "azure_env_name = 'ds-qwen-s-env'\n",
    "azure_model_name = 'ds-qwen-s-model'\n",
    "azure_endpoint_name = 'ds-qwen-s-ep'\n",
    "azure_deployment_name = 'blue'\n",
    "\n",
    "azure_serving_cluster_size = 'Standard_NC6s_v3'\n",
    "\n",
    "if IS_DEBUG:\n",
    "    logger.debug(\"===== 0. Azure ML Deployment Info =====\")\n",
    "    logger.debug(f\"AZURE_SUBSCRIPTION_ID={AZURE_SUBSCRIPTION_ID}\")\n",
    "    logger.debug(f\"AZURE_RESOURCE_GROUP={AZURE_RESOURCE_GROUP}\")\n",
    "    logger.debug(f\"AZURE_WORKSPACE={AZURE_WORKSPACE}\")\n",
    "    logger.debug(f\"HF_MODEL_NAME_OR_PATH={HF_MODEL_NAME_OR_PATH}\")\n",
    "\n",
    "    logger.debug(f\"azure_env_name={azure_env_name}\")\n",
    "    logger.debug(f\"azure_model_name={azure_model_name}\")\n",
    "    logger.debug(f\"azure_endpoint_name={azure_endpoint_name}\")\n",
    "    logger.debug(f\"azure_deployment_name={azure_deployment_name}\")\n",
    "    logger.debug(f\"azure_serving_cluster_size={azure_serving_cluster_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9843e0f-3cf1-4e86-abb7-a49919fac8d4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Serving preparation\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1. Configure workspace details\n",
    "\n",
    "To connect to a workspace, we need identifying parameters - a subscription, a resource group, and a workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle on the Azure Machine Learning workspace we need. We will use the default Azure authentication for this hands-on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb4a273-ba31-4f47-a2fd-dc8cdea390f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:23:20,428 - logger - INFO - ===== 2. Serving preparation =====\n",
      "2025-03-06 02:23:20,430 - logger - INFO - Calling DefaultAzureCredential.\n",
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
    "\n",
    "logger.info(f\"===== 2. Serving preparation =====\")\n",
    "logger.info(f\"Calling DefaultAzureCredential.\")\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    ml_client = MLClient(\n",
    "        credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a377b-d10c-413e-a67b-2c11a3cff7fd",
   "metadata": {},
   "source": [
    "### 2.2. Create model asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73532c39-3fdd-40a7-b2be-9f5a2f22443a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_model_asset(\n",
    "    ml_client,\n",
    "    model_name,\n",
    "    job_name=None,\n",
    "    model_dir=\"outputs\",\n",
    "    model_type=\"custom_model\",\n",
    "    update=False,\n",
    "):\n",
    "    try:\n",
    "        latest_model_version = max(\n",
    "            [int(m.version) for m in ml_client.models.list(name=model_name)]\n",
    "        )\n",
    "        if update:\n",
    "            raise ResourceExistsError(\"Found Model asset, but will update the Model.\")\n",
    "        else:\n",
    "            model_asset = ml_client.models.get(\n",
    "                name=model_name, version=latest_model_version\n",
    "            )\n",
    "            logger.info(f\"Found Model asset: {model_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")\n",
    "        if job_name is None:\n",
    "            model_path = model_dir\n",
    "        else:\n",
    "            model_path = (\n",
    "                f\"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/\"\n",
    "            )\n",
    "        run_model = Model(\n",
    "            name=model_name,\n",
    "            path=model_path,\n",
    "            description=\"Model created from run.\",\n",
    "            type=model_type,  # mlflow_model, custom_model, triton_model\n",
    "        )\n",
    "        model_asset = ml_client.models.create_or_update(run_model)\n",
    "        logger.info(f\"Created Model asset: {model_name}\")\n",
    "\n",
    "    return model_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aaa9671-fc98-4e5e-a70c-7771caa1c7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:23:22,490 - logger - INFO - Found Model asset: ds-qwen-s-model. Will not create again\n"
     ]
    }
   ],
   "source": [
    "model = get_or_create_model_asset(\n",
    "    ml_client,\n",
    "    azure_model_name,\n",
    "    job_name=None,\n",
    "    model_dir=\"deepseek-adapter\", # dummy model file folder\n",
    "    model_type=\"custom_model\",\n",
    "    update=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df561a-7846-4450-a2dd-4af6396b1719",
   "metadata": {},
   "source": [
    "### 2.3. Create AzureML environment\n",
    "\n",
    "Azure ML defines containers (called environment asset) in which your code will run. We can use the built-in environment or build a custom environment (Docker container, conda). This hands-on uses Docker container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac357a-3944-4702-a338-b9f4b67dadc9",
   "metadata": {},
   "source": [
    "#### Docker environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b19bc6-dc43-4948-8c71-97a033a5f5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:23:22,728 - logger - INFO - Exception: Found Environment asset, but will update the Environment.\n",
      "2025-03-06 02:23:25,029 - logger - INFO - Created Environment asset: ds-qwen-s-env\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "\n",
    "def get_or_create_docker_environment_asset(\n",
    "    ml_client, env_name, docker_dir, inference_config=None, update=False\n",
    "):\n",
    "\n",
    "    try:\n",
    "        latest_env_version = max(\n",
    "            [int(e.version) for e in ml_client.environments.list(name=env_name)]\n",
    "        )\n",
    "        if update:\n",
    "            raise ResourceExistsError(\n",
    "                \"Found Environment asset, but will update the Environment.\"\n",
    "            )\n",
    "        else:\n",
    "            env_asset = ml_client.environments.get(\n",
    "                name=env_name, version=latest_env_version\n",
    "            )\n",
    "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")\n",
    "        env_docker_image = Environment(\n",
    "            build=BuildContext(path=docker_dir),\n",
    "            name=env_name,\n",
    "            description=\"Environment created from a Docker context.\",\n",
    "            inference_config=inference_config,\n",
    "        )\n",
    "        env_asset = ml_client.environments.create_or_update(env_docker_image)\n",
    "        logger.info(f\"Created Environment asset: {env_name}\")\n",
    "\n",
    "    return env_asset\n",
    "\n",
    "\n",
    "inference_config = {\n",
    "    \"liveness_route\": {\n",
    "        \"port\": 8000,\n",
    "        \"path\": \"/health\",\n",
    "    },\n",
    "    \"readiness_route\": {\n",
    "        \"port\": 8000,\n",
    "        \"path\": \"/health\",\n",
    "    },\n",
    "    \"scoring_route\": {\n",
    "        \"port\": 8000,\n",
    "        \"path\": \"/\",\n",
    "    },\n",
    "}\n",
    "\n",
    "env = get_or_create_docker_environment_asset(\n",
    "    ml_client, azure_env_name, \"docker\", inference_config, update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb187e-370f-4481-9d82-a38ae982c1e3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Serving\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1. Create endpoint\n",
    "\n",
    "Create an endpoint. This process does not provision a GPU cluster yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c22433-4ab8-4db9-956b-7f437b86dfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:23:25,038 - logger - INFO - ===== 3. Serving =====\n",
      "2025-03-06 02:24:28,819 - logger - INFO - \n",
      "---Endpoint created successfully---\n",
      "\n",
      "2025-03-06 02:24:28,838 - logger - INFO - Creating Endpoint took 1 minute and 3.78 seconds\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    IdentityConfiguration,\n",
    "    ManagedIdentityConfiguration,\n",
    ")\n",
    "\n",
    "logger.info(f\"===== 3. Serving =====\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Check if the endpoint already exists in the workspace\n",
    "try:\n",
    "    endpoint = ml_client.online_endpoints.get(azure_endpoint_name)\n",
    "    logger.info(\"---Endpoint already exists---\")\n",
    "except:\n",
    "    # Create an online endpoint if it doesn't exist\n",
    "\n",
    "    # Define the endpoint\n",
    "    endpoint = ManagedOnlineEndpoint(\n",
    "        name=azure_endpoint_name,\n",
    "        description=f\"Test endpoint for {model.name}\",\n",
    "    )\n",
    "\n",
    "# Trigger the endpoint creation\n",
    "try:\n",
    "    ml_client.begin_create_or_update(endpoint).wait()\n",
    "    logger.info(\"\\n---Endpoint created successfully---\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(f\"Endpoint creation failed. Detailed Response:\\n{err}\") from err\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "from humanfriendly import format_timespan\n",
    "\n",
    "timespan = format_timespan(t1 - t0)\n",
    "logger.info(f\"Creating Endpoint took {timespan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a05af-0aca-4d36-9c0f-bfa4dcc6203b",
   "metadata": {},
   "source": [
    "### 3.2. Create Deployment\n",
    "\n",
    "Create a Deployment. This takes a lot of time as GPU clusters must be provisioned and the serving environment must be built.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d08ab32-5cd6-439f-bb34-13ddc200a279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_vars = {\n",
    "    \"MODEL_NAME\": HF_MODEL_NAME_OR_PATH,\n",
    "    \"VLLM_ARGS\": \"--tensor-parallel-size 1 --max-model-len 8000 --enforce-eager --dtype float16\",\n",
    "    \"HUGGING_FACE_HUB_TOKEN\": HF_TOKEN,\n",
    "}\n",
    "deployment_env_vars = {**env_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3afaa8b-5af1-49d1-990f-414da0effe8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint ds-qwen-s-ep exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 02:42:10,744 - logger - INFO - \n",
      "---Deployment created successfully---\n",
      "\n",
      "2025-03-06 02:42:12,480 - logger - INFO - Creating deployment took 17 minutes and 43.62 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 147 ms, total: 2.69 s\n",
      "Wall time: 17min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "from azure.ai.ml.entities import (    \n",
    "    OnlineRequestSettings,\n",
    "    CodeConfiguration,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    Environment\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=azure_deployment_name,\n",
    "    endpoint_name=azure_endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=azure_serving_cluster_size,\n",
    "    instance_count=1,\n",
    "    environment_variables=deployment_env_vars,    \n",
    "    environment=env,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        max_concurrent_requests_per_instance=2,\n",
    "        request_timeout_ms=180000, \n",
    "        max_queue_wait_ms=360000\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=5,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=30,\n",
    "        initial_delay=200\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=30,\n",
    "        success_threshold=1,\n",
    "        timeout=2,\n",
    "        period=10,\n",
    "        initial_delay=200,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Trigger the deployment creation\n",
    "try:\n",
    "    ml_client.begin_create_or_update(deployment).wait()\n",
    "    logger.info(\"\\n---Deployment created successfully---\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(\n",
    "        f\"Deployment creation failed. Detailed Response:\\n{err}\"\n",
    "    ) from err\n",
    "    \n",
    "endpoint.traffic = {azure_deployment_name: 100}\n",
    "endpoint_poller = ml_client.online_endpoints.begin_create_or_update(endpoint)\n",
    "\n",
    "t1 = time.time()\n",
    "timespan = format_timespan(t1 - t0)\n",
    "logger.info(f\"Creating deployment took {timespan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f7dfe9-e27e-449d-a5cb-425663651c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_results = endpoint_poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae58e5f-999f-449e-b5ac-c766c184715f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth_mode: key\n",
      "description: Test endpoint for ds-qwen-s-model\n",
      "id: /subscriptions/e56790f8-0506-49eb-95b8-82817828d59d/resourceGroups/dev/providers/Microsoft.MachineLearningServices/workspaces/test-vllm/onlineEndpoints/ds-qwen-s-ep\n",
      "identity:\n",
      "  principal_id: 72c1c2d1-1259-44c4-9ca4-15a5b53e0988\n",
      "  tenant_id: 16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "  type: system_assigned\n",
      "kind: Managed\n",
      "location: westeurope\n",
      "mirror_traffic: {}\n",
      "name: ds-qwen-s-ep\n",
      "openapi_uri: https://ds-qwen-s-ep.westeurope.inference.ml.azure.com/swagger.json\n",
      "properties:\n",
      "  AzureAsyncOperationUri: https://management.azure.com/subscriptions/e56790f8-0506-49eb-95b8-82817828d59d/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oeidp:10331bed-c16d-4680-834e-e054c4eeaeb9:43dae400-6b4f-40fb-ab2b-480d084c771a?api-version=2022-02-01-preview\n",
      "  azureml.onlineendpointid: /subscriptions/e56790f8-0506-49eb-95b8-82817828d59d/resourcegroups/dev/providers/microsoft.machinelearningservices/workspaces/test-vllm/onlineendpoints/ds-qwen-s-ep\n",
      "  createdAt: 2025-03-06T02:23:28.083730+0000\n",
      "  createdBy: Jihua Liu\n",
      "  lastModifiedAt: 2025-03-06T02:42:11.953450+0000\n",
      "provisioning_state: Succeeded\n",
      "public_network_access: enabled\n",
      "scoring_uri: https://ds-qwen-s-ep.westeurope.inference.ml.azure.com/\n",
      "tags: {}\n",
      "traffic:\n",
      "  blue: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(endpoint_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de81f846-58e0-4717-92ac-9871787e7a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = endpoint_results.name\n",
    "keys = ml_client.online_endpoints.get_keys(name=endpoint_name)\n",
    "primary_key = keys.primary_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f437f6-153a-42d5-ab22-0011d0fe2481",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. Test\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1. Invocation\n",
    "\n",
    "Try calling the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b67088d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your prompt\n",
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps customers find information. As an assistant, you respond to questions in a concise and unique manner.\n",
    "You can use Markdown to answer simply and concisely, and add a personal touch with appropriate emojis.\n",
    "\n",
    "Add a witty joke starting with \"By the way,\" at the end of your response. Do not mention the customer's name in the joke part.\n",
    "The joke should be related to the specific question asked.\n",
    "For example, if the question is about tents, the joke should be specifically related to tents.\n",
    "\n",
    "Use the given context to provide a more personalized response. Write each sentence on a new line:\n",
    "\"\"\"\n",
    "context = \"\"\"\n",
    "    The Alpine Explorer Tent features a detachable partition to ensure privacy, \n",
    "    numerous mesh windows and adjustable vents for ventilation, and a waterproof design. \n",
    "    It also includes a built-in gear loft for storing outdoor essentials. \n",
    "    In short, it offers a harmonious blend of privacy, comfort, and convenience, making it a second home in nature!\n",
    "\"\"\"\n",
    "question = \"What are features of the Alpine Explorer Tent?\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4a9ac5-5b4e-4211-83e1-9b4872642022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_remote = ml_client.online_endpoints.get(name=azure_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43202fcb-66de-4809-bcc0-18f34ce87e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ds-qwen-s-ep.westeurope.inference.ml.azure.com/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_remote.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d16724-eb98-4675-a1da-4e6c7f8cdfe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PLANE_TOKEN = ml_client.online_endpoints.get_keys(name=azure_endpoint_name).primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76f70ce-7aa9-4913-a761-c9d4020eaee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 0 ns, total: 21 ms\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "url = os.path.join(endpoint_remote.scoring_uri, \"v1/completions\")\n",
    "\n",
    "api_key = DATA_PLANE_TOKEN\n",
    "# Set the headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "prompt = f\"\"\"{system_message}\\n### Instruction:\\n{user_message}\\n\\n### Response:\"\"\"\n",
    "\n",
    "data = {\n",
    "    \"model\": model_path,\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data, timeout=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0960569f-01c1-412f-991a-fb299295f344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The Alpine Explorer Tent is a unique tent designed for outdoor adventures. It features a detachable partition to ensure privacy, numerous mesh windows for ventilation, and a waterproof design to protect against the elements. Additionally, it includes a built-in gear loft for storing outdoor gear, making it ideal for both comfort and convenience. It's a perfect second home to nature! By the way, consider booking it before it's sold out. 🌞\n",
      "</think>\n",
      "\n",
      "The Alpine Explorer Tent is a unique tent designed for outdoor adventures. It features a detachable partition to ensure privacy, numerous mesh windows for ventilation, and a waterproof design to protect against the elements. Additionally, it includes a built-in gear loft for storing outdoor gear, making it ideal for both comfort and convenience. It's a perfect second home to nature! By the way, consider booking it before it's sold out. 🌞\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d96bd-75da-4c10-923c-edad899fc4d3",
   "metadata": {},
   "source": [
    "### 4.2. LLM latency/throughput simple benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb105465-85dd-49ee-a45f-403f7d0c9d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "def simple_llm_benchmark(\n",
    "    messages: list,\n",
    "    model_path: str = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    num_warmups: int = 1,\n",
    "    num_infers: int = 5,\n",
    "    **params: dict,\n",
    ") -> dict:\n",
    "\n",
    "    print(\"=== Measuring latency ===\")\n",
    "    print(f\"model_path={model_path}, num_infers={num_infers}, params={params}\")\n",
    "\n",
    "    latencies = []\n",
    "    # Warm up\n",
    "    for _ in range(num_warmups):\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=120)\n",
    "    print(\"=== Warmup done. Start Benchmarking... ===\")\n",
    "    begin = time.time()\n",
    "    # Timed run\n",
    "    for curr_infer in range(num_infers):\n",
    "        start_time = perf_counter()\n",
    "        if (curr_infer % 5) == 0:\n",
    "            print(f\"Inferring {curr_infer}th...\")\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=120)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    end = time.time()\n",
    "\n",
    "    # Compute run statistics\n",
    "    duration = end - begin\n",
    "    time_avg_sec = np.mean(latencies)\n",
    "    time_std_sec = np.std(latencies)\n",
    "    time_p95_sec = np.percentile(latencies, 95)\n",
    "    time_p99_sec = np.percentile(latencies, 99)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"duration\": duration,\n",
    "        \"avg_sec\": time_avg_sec,\n",
    "        \"std_sec\": time_std_sec,\n",
    "        \"p95_sec\": time_p95_sec,\n",
    "        \"p99_sec\": time_p99_sec,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8827fb45-c7ab-4aa8-b9f4-1c4e610d695a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Measuring latency ===\n",
      "model_path=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, num_infers=10, params={'max_tokens': 100, 'temperature': 0.5}\n",
      "=== Warmup done. Start Benchmarking... ===\n",
      "Inferring 0th...\n",
      "Inferring 5th...\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "params = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.5,\n",
    "}\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "metrics = simple_llm_benchmark(messages, model_path=model_path, num_warmups=1, num_infers=10, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa138375-6751-4502-91ea-29b3b3725a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_sec': np.float64(4.8015740680973975),\n",
      " 'duration': 48.01575684547424,\n",
      " 'p95_sec': np.float64(6.214138701820048),\n",
      " 'p99_sec': np.float64(6.225013119593496),\n",
      " 'std_sec': np.float64(1.8616714527749252)}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834a237-e751-446a-ac21-7272c29b0c2c",
   "metadata": {},
   "source": [
    "## Clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc72663d-d773-435b-871f-cc51b1e51763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f42b072d540>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................."
     ]
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_delete(azure_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c783a0-38e4-4a27-991b-5cb8eb9f2a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
